{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41b2704-74fa-489c-95f9-af33a1274ce8",
   "metadata": {},
   "source": [
    "# 使用 AWQ 算法量化 Facebook OPT-2.7B 模型¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fdf098-536f-42fb-8170-19092f6f21f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/transformers/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-19 22:57:48.234898: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-19 22:57:48.236820: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-19 22:57:48.263007: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-19 22:57:48.263040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-19 22:57:48.263602: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-19 22:57:48.268270: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-19 22:57:48.968080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = \"facebook/opt-2.7b\"\n",
    "\n",
    "generator = pipeline('text-generation',\n",
    "                     model=model_path,\n",
    "                     device=0,\n",
    "                     do_sample=True,\n",
    "                     num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba6e8ad-5771-403b-9be6-c6005fad4c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The woman worked as a bank teller and in a car dealership and was a frequent shoplifter'},\n",
       " {'generated_text': 'The woman worked as a flight attendant in a regional flying from Newark to John F Kennedy International Airport.'},\n",
       " {'generated_text': 'The woman worked as a caregiver for one of the residents at a nursing home. The elderly woman'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"The woman worked as a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e1889-1844-49b3-b324-ff53608bb4fc",
   "metadata": {},
   "source": [
    "## 使用 AutoAWQ 量化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81b4208b-4837-4737-baae-7155ead934cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 8 files: 100%|██████████████████████████| 8/8 [00:00<00:00, 107202.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "quant_path = \"../models/opt-2.7b-awq\"\n",
    "quant_config = {\"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\":\"GEMM\"}\n",
    "\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_path,device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,trust_remote_code = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e6332fe-cebb-4b29-8840-3c82af30cddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "AWQ: 100%|██████████████████████████████████████| 32/32 [1:36:52<00:00, 181.64s/it]\n"
     ]
    }
   ],
   "source": [
    "model.quantize(tokenizer,quant_config=quant_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f3990-3edd-442e-8b8a-21554ff6b412",
   "metadata": {},
   "source": [
    "## Transformers 兼容性配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ede83d7-ee2a-4eb4-aeeb-fd96b693c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AwqConfig, AutoConfig\n",
    "\n",
    "quantization_config = AwqConfig(\n",
    "    bits = quant_config[\"w_bit\"],\n",
    "    group_size = quant_config[\"q_group_size\"],\n",
    "    zero_point = quant_config[\"zero_point\"],\n",
    "    version = quant_config[\"version\"].lower()\n",
    ").to_dict()\n",
    "\n",
    "model.model.config.quantization_config = quantization_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48235fb3-4fc4-4baf-a8b5-8dac4458e53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/opt-2.7b-awq/tokenizer_config.json',\n",
       " '../models/opt-2.7b-awq/special_tokens_map.json',\n",
       " '../models/opt-2.7b-awq/vocab.json',\n",
       " '../models/opt-2.7b-awq/merges.txt',\n",
       " '../models/opt-2.7b-awq/added_tokens.json',\n",
       " '../models/opt-2.7b-awq/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_quantized(quant_path)\n",
    "tokenizer.save_pretrained(quant_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ad7e3-2d10-48bb-8329-b826668912e5",
   "metadata": {},
   "source": [
    "## 使用 GPU 加载量化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a87c0dc-e269-42ee-b233-7286999e2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(quant_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(quant_path,device_map=\"cuda\").to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b80a75a0-5722-400f-a25d-adb4e8e95c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text):\n",
    "    inputs = tokenizer(text,return_tensors=\"pt\").to(0)\n",
    "\n",
    "    out = model.generate(**inputs,max_new_tokens=128)\n",
    "    return tokenizer.decode(out[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b30a121-6316-40cc-9c0d-f65f86994ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merry Christmas! I'm glad to see that the first month of NoFap is proving to be one which I hope to repeat!\n",
      "No way, are you one of those 90% who relapse after one month? That's awesome man and I don't know how you accomplished that, but I'm definitely proud of you!!\n"
     ]
    }
   ],
   "source": [
    "result = generate_text(\"Merry Christmas! I'm glad to\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1aaf2e-c9ed-4637-8a45-99ab115d83c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
